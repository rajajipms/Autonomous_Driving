{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "#import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary items from Keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dropout, UpSampling2D, concatenate, Input\n",
    "from keras.layers import Conv2DTranspose, Conv2D, MaxPooling2D\n",
    "## Dont use it----->from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "##Dont use this-->from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "train_images = pickle.load(open(\"full_CNN_train.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load image labels\n",
    "labels = pickle.load(open(\"full_CNN_labels.p\", \"rb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make into arrays as the neural network wants these\n",
    "train_images = np.array(train_images)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize labels - training images get normalized to start in the network\n",
    "labels = labels / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shuffle images along with their labels, then split into training/validation sets\n",
    "train_images, labels = shuffle(train_images, labels)\n",
    "# Test size may be 10% or 20%\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Batch size, epochs and pool size below are all paramaters to fiddle with for optimization\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "pool_size = (2, 2)\n",
    "#input_shape = X_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here is the actual neural network ###\n",
    "# Normalizes incoming inputs. First layer needs the input shape to work\n",
    "#BatchNormalization(input_shape=input_shape)\n",
    "Inputs = Input(batch_shape=(None, 80, 160, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Below layers were re-named for easier reading of model summary; this not necessary\n",
    "# Conv Layer 1\n",
    "Conv1 = Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Inputs)\n",
    "Bat1 = BatchNormalization()(Conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv Layer 2\n",
    "Conv2 = Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Conv1)\n",
    "Bat2 = BatchNormalization()(Conv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pooling 1\n",
    "Pool1 = MaxPooling2D(pool_size=pool_size)(Conv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conv Layer 3\n",
    "Conv3 = Conv2D(32, (3, 3), padding = 'valid', strides=(1,1), activation = 'relu')(Pool1)\n",
    "#Drop3 = Dropout(0.2)(Conv3)\n",
    "Bat3 = BatchNormalization()(Conv3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv Layer 4\n",
    "Conv4 = Conv2D(32, (3, 3), padding = 'valid', strides=(1,1), activation = 'relu')(Bat3)\n",
    "#Drop4 = Dropout(0.5)(Conv4)\n",
    "Bat4 = BatchNormalization()(Conv4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv Layer 5\n",
    "Conv5 = Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Bat4)\n",
    "#Drop5 = Dropout(0.2)(Conv5)\n",
    "Bat5 = BatchNormalization()(Conv5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pooling 2\n",
    "Pool2 = MaxPooling2D(pool_size=pool_size)(Bat5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv Layer 6\n",
    "Conv6 = Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Pool2)\n",
    "#Drop6 = Dropout(0.2)(Conv6)\n",
    "Bat6 = BatchNormalization()(Conv6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conv Layer 7\n",
    "Conv7 = Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Bat6)\n",
    "#Drop7 = Dropout(0.2)(Conv7)\n",
    "Bat7 = BatchNormalization()(Conv7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling 3\n",
    "Pool3 = MaxPooling2D(pool_size=pool_size)(Bat7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conv Layer 8\n",
    "Conv8 = Conv2D(128, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Pool3)\n",
    "#Drop8 = Dropout(0.2)(Conv8)\n",
    "Bat8 = BatchNormalization()(Conv8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conv Layer 9\n",
    "Conv9 = Conv2D(128, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Bat8)\n",
    "#Drop9 = Dropout(0.2)(Conv9)\n",
    "Bat9 = BatchNormalization()(Conv9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pooling 4\n",
    "Pool4 = MaxPooling2D(pool_size=pool_size)(Bat9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Upsample 1 to Deconv 1\n",
    "Deconv1 = Conv2DTranspose(128, (2, 2), padding='valid', strides=(2,2), activation = 'relu')(Pool4)\n",
    "#Up1 = UpSampling2D(size=pool_size)(Pool4)\n",
    "Mer1 = concatenate([Deconv1, Bat9], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Deconv 2\n",
    "Deconv2 = Conv2DTranspose(128, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Mer1)\n",
    "DBat2 = BatchNormalization()(Deconv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deconv 3\n",
    "Deconv3 = Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(DBat2)\n",
    "DBat3 = BatchNormalization()(Deconv3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Upsample 2 to Deconv 4\n",
    "Deconv4 = Conv2DTranspose(64, (2, 2), padding='valid', strides=(2,2), activation = 'relu')(DBat3)\n",
    "#Up2 = UpSampling2D(size=pool_size)(DBat2)\n",
    "Mer2 = concatenate([Deconv4, Bat7], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deconv 5\n",
    "Deconv5 = Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Mer2)\n",
    "DBat5 = BatchNormalization()(Deconv5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Deconv 6\n",
    "Deconv6 = Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(DBat5)\n",
    "DBat6 = BatchNormalization()(Deconv6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Upsample 3 to Deconv 7\n",
    "Deconv7 = Conv2DTranspose(32, (2, 2), padding='valid', strides=(2,2), activation = 'relu')(DBat6)\n",
    "#Up3 = UpSampling2D(size=pool_size)(DBat4)\n",
    "Mer3 = concatenate([Deconv7, Bat5], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Deconv 8\n",
    "Deconv8 = Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Mer3)\n",
    "DBat8 = BatchNormalization()(Deconv8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deconv 9\n",
    "Deconv9 = Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(DBat8)\n",
    "DBat9 = BatchNormalization()(Deconv9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Deconv 10\n",
    "Deconv10 = Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(DBat9)\n",
    "DBat10 = BatchNormalization()(Deconv10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Upsample 4 to Deconv 11\n",
    "Deconv11 = Conv2DTranspose(16, (2, 2), padding='valid', strides=(2,2), activation = 'relu')(DBat10)\n",
    "#Up4 = UpSampling2D(size=pool_size)(DBat7)\n",
    "Mer4 = concatenate([Deconv11, Bat2], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Deconv 12\n",
    "Deconv12 = Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Mer4)\n",
    "DBat12 = BatchNormalization()(Deconv12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Deconv 13\n",
    "Deconv13 = Conv2DTranspose(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(DBat12)\n",
    "DBat13 = BatchNormalization()(Deconv13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final layer - only including one channel so 1 filter\n",
    "Final = Conv2DTranspose(1, (3, 3), padding='same', strides=(1,1), activation = 'relu')(DBat13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### End of network ###\n",
    "model = Model(inputs=Inputs, outputs=Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using a generator to help the model use less data\n",
    "# Channel shifts help with shadows slightly\n",
    "datagen = ImageDataGenerator(channel_shift_range=0.2)\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-6adad4d76f8e>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=len(X_train)/batch_size,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "717/717 [==============================] - 730s 1s/step - loss: 0.0196 - val_loss: 0.0054\n",
      "Epoch 2/10\n",
      "717/717 [==============================] - 718s 996ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 3/10\n",
      "717/717 [==============================] - 713s 989ms/step - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 4/10\n",
      "717/717 [==============================] - 717s 994ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 5/10\n",
      "717/717 [==============================] - 716s 993ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 6/10\n",
      "717/717 [==============================] - 718s 996ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 7/10\n",
      "717/717 [==============================] - 714s 990ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "717/717 [==============================] - 714s 990ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "717/717 [==============================] - 727s 1s/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "717/717 [==============================] - 632s 874ms/step - loss: 0.0019 - val_loss: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c7b7fb0580>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compiling and training the model\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=len(X_train)/batch_size,\n",
    "epochs=epochs, verbose=1, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Freeze layers since training is done\n",
    "model.trainable = False\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model architecture and weights\n",
    "model.save('full_CNN2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\samji\\anaconda3\\lib\\site-packages (from pydot) (2.4.7)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\samji\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\samji\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\samji\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\samji\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\samji\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\samji\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\samji\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 80, 160, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 78, 158, 16)  448         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 76, 156, 16)  2320        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 38, 78, 16)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 36, 76, 32)   4640        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 36, 76, 32)  128         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 34, 74, 32)   9248        ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 34, 74, 32)  128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 72, 32)   9248        ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 72, 32)  128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 36, 32)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 14, 34, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 14, 34, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 12, 32, 64)   36928       ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 12, 32, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 6, 16, 64)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 4, 14, 128)   73856       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 14, 128)  512         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 2, 12, 128)   147584      ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 2, 12, 128)  512         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 6, 128)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 2, 12, 128)  65664       ['max_pooling2d_3[0][0]']        \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2, 12, 256)   0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 4, 14, 128)  295040      ['concatenate[0][0]']            \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 4, 14, 128)  512         ['conv2d_transpose_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 6, 16, 64)   73792       ['batch_normalization_9[0][0]']  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 6, 16, 64)   256         ['conv2d_transpose_2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 12, 32, 64)  16448       ['batch_normalization_10[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 12, 32, 128)  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 14, 34, 64)  73792       ['concatenate_1[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 14, 34, 64)  256         ['conv2d_transpose_4[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 16, 36, 32)  18464       ['batch_normalization_11[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 36, 32)  128         ['conv2d_transpose_5[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 32, 72, 32)  4128        ['batch_normalization_12[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32, 72, 64)   0           ['conv2d_transpose_6[0][0]',     \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 34, 74, 32)  18464       ['concatenate_2[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 34, 74, 32)  128         ['conv2d_transpose_7[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 36, 76, 16)  4624        ['batch_normalization_13[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 36, 76, 16)  64          ['conv2d_transpose_8[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 38, 78, 16)  2320        ['batch_normalization_14[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 38, 78, 16)  64          ['conv2d_transpose_9[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 76, 156, 16)  1040       ['batch_normalization_15[0][0]'] \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 76, 156, 16)  64         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 76, 156, 32)  0           ['conv2d_transpose_10[0][0]',    \n",
      "                                                                  'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 78, 158, 16)  4624       ['concatenate_3[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 78, 158, 16)  64         ['conv2d_transpose_11[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_12 (Conv2DTra  (None, 80, 160, 8)  1160        ['batch_normalization_16[0][0]'] \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 80, 160, 8)  32          ['conv2d_transpose_12[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_13 (Conv2DTra  (None, 80, 160, 1)  73          ['batch_normalization_17[0][0]'] \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 885,889\n",
      "Trainable params: 0\n",
      "Non-trainable params: 885,889\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# Show summary of model\n",
    "model.summary()\n",
    "plot_model(model, to_file='model.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2972f795f882>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'arr' is not defined"
     ]
    }
   ],
   "source": [
    "import skimage.transform as st\n",
    "\n",
    "st.resize(arr, (100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy\n",
    "#img_resized= np.array(Image.fromarray(obj=img, mode='F').resize(size=(width, height), resample=Image.BICUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('full_CNN2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###class Lanes():\n",
    "    def __init__(self):\n",
    "        self.recent_fit = []\n",
    "        self.average_fit = []\n",
    "\n",
    "def road_lines(image):\n",
    "    small_image = Image.fromarray(image).resize(size=(160,80))\n",
    "    small_image = np.array(small_image)\n",
    "    small_image = small_image[None,:,:,:]\n",
    "    \n",
    "    prediction = model.predict(small_image)[0]*255;\n",
    "    lanes.recent_fit.append(prediction)\n",
    "    \n",
    "    if(len(lanes.recent_fit)>5):\n",
    "        lanes.recent_fit = lanes.recent_fit[1:]\n",
    "    \n",
    "    lanes.average_fit = np.mean(np.array([i for i in lanes.recent_fit]), axis = 0)\n",
    "    \n",
    "    blanks = np.zeros_like(lanes.average_fit)\n",
    "    lane_drawn = np.dstack((blanks, lanes.average_fit, blanks))\n",
    "    \n",
    "    lane_image = Image.fromarray(image).resize(size=(1280,720))\n",
    "    lane_image = np.array(lane_image)\n",
    "    result = cv2.addWeighted(image, 1, lane_image, 1, 0)\n",
    "    \n",
    "    return result            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class Lane \n",
    "\n",
    "# Class to average lanes with\n",
    "class Lanes():\n",
    "    def __init__(self):\n",
    "        self.recent_fit = []\n",
    "        self.avg_fit = []\n",
    "        \n",
    "# resize the image and predict the lane to be drawn from the model in G color\n",
    "\n",
    "def road_lines_image(image):\n",
    "    \n",
    "    img_arr = cv2.imread(image)\n",
    "    actual_image = imresize(img_arr, (720, 1280, 3))\n",
    "\n",
    "    # Get image ready for feeding into model\n",
    "    img = mpimg.imread(image)\n",
    "    small_img_2 = imresize(img, (80, 160, 3))\n",
    "    small_img_1= np.array(small_img_2)\n",
    "    small_img = small_img_1[None, :, :, :]\n",
    "\n",
    "    # Make prediction with neural network (un-normalize value by multiplying by 255)\n",
    "    prediction = model.predict(small_img)[0] * 255\n",
    "\n",
    "    # Add lane prediction to list for averaging\n",
    "    lanes.recent_fit.append(prediction)\n",
    "    # Only using last five for average\n",
    "    if len(lanes.recent_fit) > 5:\n",
    "        lanes.recent_fit = lanes.recent_fit[1:]\n",
    "        \n",
    "    # Calculate average detection\n",
    "    lanes.avg_fit = np.mean(np.array([i for i in lanes.recent_fit]), axis = 0)\n",
    "\n",
    "    # Generate fake R & B color dimensions, stack with G\n",
    "    blanks = np.zeros_like(lanes.avg_fit).astype(np.uint8)\n",
    "    lane_drawn = np.dstack((blanks, lanes.avg_fit, blanks))\n",
    "\n",
    "    # Re-size to match the original image\n",
    "    lane_image = imresize(lane_drawn, (720, 1280, 3))\n",
    "\n",
    "    # Merge the lane drawing onto the original image\n",
    "    result = cv2.addWeighted(actual_image, 1, lane_image, 1, 0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imresize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e0822765e5aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msuccess\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlanes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLanes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroad_lines_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mimS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Lane\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-bf7f78e56758>\u001b[0m in \u001b[0;36mroad_lines_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#img_arr = cv2.imread(image)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mimg_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mactual_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m720\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1280\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Get image ready for feeding into model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imresize' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('lanes_clip.mp4')\n",
    "pTime = 0\n",
    "while(cap.isOpened()==True):\n",
    "    success , img = cap.read()\n",
    "    lanes = Lanes()\n",
    "    img = road_lines_image(img)\n",
    "    imS = cv2. resize(img, (600, 600))\n",
    "    cv2.imshow(\"Lane\",imS)\n",
    "    if cv2.waitKey(10)==ord('q'):\n",
    "        print(\"finish\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the lane detector \n",
    "\n",
    "#create a lanes object\n",
    "lanes = Lanes()\n",
    "\n",
    "for path in glob.glob('test_images/*.jpg'):\n",
    "    res_img = road_lines_image(path)\n",
    "    names = [os.path.basename(x) for x in glob.glob(path)]   \n",
    "    out_path = 'test_predict/'+names[0]\n",
    "    # save the result in a image\n",
    "    cv2.imwrite(out_path,res_img)\n",
    "    \n",
    "    \n",
    "    predicted_images = [plt.imread(path) for path in glob.glob('test_predict/*.jpg')]\n",
    "\n",
    "    show_images(predicted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('full_CNN2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "8/8 [==============================] - 47s 3s/step - loss: 6257.8013\n",
      "test loss, test acc: 6257.80126953125\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = loaded_model.evaluate(X_val, y_val, batch_size=180)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
